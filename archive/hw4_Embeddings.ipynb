{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–ó 4 \n",
    "## W2V, bert, –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __–ó–∞–¥–∞—á–∞__1:\n",
    "\n",
    "–†–µ–∞–ª–∏–∑—É–π—Ç–µ –ø–æ–∏—Å–∫, –≥–¥–µ\n",
    "- –º–µ—Ç–æ–¥ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ - **fasttext** (–º–æ–¥–µ–ª—å araneum_none_fasttextcbow_300_5_2018) –∏ **Bert** (–º–æ–¥–µ–ª—å sbert_large_nlu_ru)\n",
    "- —Ñ–æ—Ä–º–∞—Ç —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ - **–º–∞—Ç—Ä–∏—Ü–∞ Document-Term**\n",
    "- –º–µ—Ç—Ä–∏–∫–∞ –±–ª–∏–∑–æ—Å—Ç–∏ –ø–∞—Ä (–∑–∞–ø—Ä–æ—Å, –¥–æ–∫—É–º–µ–Ω—Ç) - **–∫–æ—Å–∏–Ω—É—Å**, –æ–Ω –∂–µ dot –Ω–∞ –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–∞—Ö \n",
    "\n",
    "–í —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤—Å–µ —Ç–æ –∂–µ, —á—Ç–æ –≤c–µ–≥–¥–∞:\n",
    "- —Ñ—É–Ω–∫—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∫–æ—Ä–ø—É—Å–∞\n",
    "- —Ñ—É–Ω–∫—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞\n",
    "- —Ñ—É–Ω–∫—Ü–∏—è —Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø–æ–¥—Å—á–µ—Ç–∞ –±–ª–∏–∑–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–æ—Ä–ø—É—Å–∞\n",
    "- –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –≤—Å–µ —ç—Ç–æ –≤–º–µ—Å—Ç–µ; –Ω–∞ –≤—Ö–æ–¥–µ - –∑–∞–ø—Ä–æ—Å, –Ω–∞ –≤—ã—Ö–æ–¥–µ - –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –Ω–µ—Å–∫–æ–ª—å–∫–æ (5) —Ç–µ–∫—Å—Ç–æ–≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n",
    "\n",
    "–°–æ—Ä—Ç–∏—Ä–æ–≤–∫—É –Ω–∞–¥–æ —Å–¥–µ–ª–∞—Ç—å **<font color='green'>–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ</font>** —á–µ—Ä–µ–∑ –º–∞—Å–∫—É; –ø—Ä–∏ –Ω–µ —Å–æ–±–ª—é–¥–µ–Ω–∏–∏ –º–∏–Ω—É—Å –¥–≤–∞ –±–∞–ª–ª–∞. –†–µ—à–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å  **<font color='green'> –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–∞–±–æ—Ç—ã</font>**; –ø—Ä–∏ –Ω–µ —Å–æ–±–ª—é–¥–µ–Ω–∏–∏ –º–∏–Ω—É—Å –±–∞–ª–ª –∑–∞ –∫–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç.\n",
    "\n",
    "\n",
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –∫–æ—Ä–ø—É—Å–∞ –≤–æ–∑—å–º–∏—Ç–µ –∫–æ—Ä–ø—É—Å –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ —Å –û—Ç–≤–µ—Ç—ã –ú–µ–π–ª üëç\n",
    "–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ —Å—Å—ã–ª–∫–µ. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–æ—Ä–ø—É—Å–∞ –±–µ—Ä–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫–ª—é—á–∞ *answers*, –Ω–æ –Ω–µ –≤—Å–µ, –∞ –æ–¥–∏–Ω, —É –∫–æ—Ç–æ—Ä–æ–≥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π *value*. –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ 50000. \n",
    "\n",
    "\n",
    "**–ù–∞ —á—Ç–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ —ç—Ç–∞ –∑–∞–¥–∞—á–∞:** \n",
    "–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–æ–≤–∏–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥—Ä—É–≥–∏—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∞ –∏–º–µ–Ω–Ω–æ fasttext –∏ Bert.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __–ó–∞–¥–∞—á–∞__2:\n",
    "**–°—Ä–∞–≤–Ω–∏—Ç–µ** –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç–æ–¥–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏, –∞ –∏–º–µ–Ω–Ω–æ:\n",
    "1. CountVectorizer\n",
    "2. TfidfVectorizer\n",
    "3. BM25\n",
    "4. fasttext\n",
    "5. bert\n",
    "\n",
    "–í —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å:\n",
    "- —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å—á–∏—Ç–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É –Ω–∞ —Ç–æ–ø-5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –ª–æ–≥–∏–∫–µ, –æ–ø–∏—Å–∞–Ω–Ω–æ–π –≤ –ª–µ–∫—Ü–∏–∏\n",
    "\n",
    "\n",
    "üëâ –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –Ω—É–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –º–µ—Ç–æ–¥—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\trekc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from scipy import sparse\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from time import time\n",
    "\n",
    "\n",
    "m = Mystem()\n",
    "nltk.download('stopwords')\n",
    "stopword = stopwords.words('russian')\n",
    "punctuation += '...' + '‚Äî' + '‚Ä¶' + '¬´¬ª'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_processing(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        corpus = list(f)[:10500]\n",
    "\n",
    "    answers_corpus = []\n",
    "    dropped = []\n",
    "    \n",
    "    for i, part in enumerate(corpus):\n",
    "        d = dict()\n",
    "        j_answers = json.loads(part)['answers']\n",
    "\n",
    "        try: # –±—ã–≤–∞–µ—Ç –ø—É—Å—Ç–æ–µ –ø–æ–ª–µ answers\n",
    "            for ind, gr_comments in enumerate(j_answers):\n",
    "\n",
    "                try:\n",
    "                    d[ind] = int(gr_comments['author_rating']['value'])\n",
    "\n",
    "                except ValueError: # –±—ã–≤–∞–µ—Ç –ø—É—Å—Ç–æ–µ –ø–æ–ª–µ value\n",
    "                    d[ind] = 0\n",
    "\n",
    "            ind = sorted(d.items(), key=lambda item: item[1], reverse=True)[0][0]\n",
    "            answers_corpus.append(j_answers[ind]['text'])\n",
    "\n",
    "        except IndexError:\n",
    "            dropped.append(i)\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    questions_corpus = []\n",
    "\n",
    "    for i, part in enumerate(corpus):\n",
    "        if i not in dropped:\n",
    "            questions_corpus.append(json.loads(part)['question'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return answers_corpus, questions_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_corpus, questions_corpus = first_processing('questions_about_love.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10171"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_processing(given_corpus):\n",
    "    corpus = []\n",
    "    dropped = []\n",
    "    for text in given_corpus:\n",
    "        text = re.sub('[0-9a-zA-Z]+', '', text)\n",
    "        text = [word.lower().strip().strip(punctuation) for word in text.split()]\n",
    "        #text = [x for x in text if x not in stopword]\n",
    "        text = ' '.join([word for word in text if word != ''])\n",
    "        corpus.append(text)\n",
    "    \n",
    "    # —á—Ç–æ–±—ã —É–¥–∞–ª–∏—Ç—å –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Ö –∏–Ω–¥–µ–∫—Å—ã\n",
    "    # —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å –∏—Ö –≤ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
    "    for ind, text in enumerate(corpus):\n",
    "        if not text:\n",
    "            dropped.append(ind)\n",
    "            del corpus[ind]\n",
    "        if text == '':\n",
    "            dropped.append(ind)\n",
    "            del corpus[ind]        \n",
    "        \n",
    "    lol = lambda lst, sz: [lst[i:i+sz] for i in range(0, len(lst), sz)]\n",
    "    txtpart = lol(corpus, 1000)\n",
    "    res = []\n",
    "    for txtp in txtpart:\n",
    "        alltexts = ' '.join([txt + ' br ' for txt in txtp])\n",
    "        words = m.lemmatize(alltexts)\n",
    "        doc = []\n",
    "        for txt in words:\n",
    "            if txt != '\\n' and txt.strip() != '':\n",
    "                if txt == 'br':\n",
    "                    res.append(' '.join(doc))\n",
    "                    doc = []\n",
    "                else:\n",
    "                    doc.append(txt)\n",
    "\n",
    "    return res, dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleared_corpus(answers_corpus, questions_corpus):\n",
    "    cleared_answers_corpus, ans_dropped = second_processing(answers_corpus)\n",
    "    \n",
    "    for ind in ans_dropped:\n",
    "        del questions_corpus[ind]\n",
    "    \n",
    "    for ind in ans_dropped:\n",
    "        del answers_corpus[ind]\n",
    "        \n",
    "    cleared_questions_corpus, ques_dropped = second_processing(questions_corpus)\n",
    "    \n",
    "    for ind in ques_dropped:\n",
    "        del cleared_answers_corpus[ind]\n",
    "    \n",
    "    for ind in ques_dropped:\n",
    "        del questions_corpus[ind]\n",
    "\n",
    "    for ind in ques_dropped:\n",
    "        del answers_corpus[ind]\n",
    "    \n",
    "    return answers_corpus, questions_corpus, cleared_answers_corpus, cleared_questions_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_corpus, questions_corpus, cleared_answers_corpus, cleared_questions_corpus = get_cleared_corpus(answers_corpus, questions_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10095"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('answers_corpus.pickle', 'wb') as f:\n",
    "#     pickle.dump(answers_corpus, f)\n",
    "    \n",
    "# with open('questions_corpus.pickle', 'wb') as f:\n",
    "#     pickle.dump(questions_corpus, f)\n",
    "    \n",
    "# with open('cleared_answers_corpus.pickle', 'wb') as f:\n",
    "#     pickle.dump(cleared_answers_corpus, f)\n",
    "    \n",
    "# with open('cleared_questions_corpus.pickle', 'wb') as f:\n",
    "#     pickle.dump(cleared_questions_corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers_corpus.pickle', 'rb') as f:\n",
    "    answers_corpus = pickle.load(f)\n",
    "    \n",
    "with open('questions_corpus.pickle', 'rb') as f:\n",
    "    questions_corpus = pickle.load(f)\n",
    "    \n",
    "with open('cleared_answers_corpus.pickle', 'rb') as f:\n",
    "    cleared_answers_corpus = pickle.load(f)\n",
    "    \n",
    "with open('cleared_questions_corpus.pickle', 'rb') as f:\n",
    "    cleared_questions_corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9595"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleared_questions_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "fasttext_model = KeyedVectors.load('araneum_none_fasttextcbow_300_5_2018.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_get_matrix(texts):\n",
    "    fasttext_vectors = []\n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = text.split()\n",
    "        tokens_vectors = np.zeros((len(tokens), fasttext_model.vector_size))\n",
    "        for i, token in enumerate(tokens):\n",
    "            tokens_vectors[i] = fasttext_model[token]\n",
    "        if tokens_vectors.shape[0] != 0:\n",
    "            means = np.mean(tokens_vectors, axis=0)\n",
    "            n_means = means / np.linalg.norm(means)\n",
    "\n",
    "        fasttext_vectors.append(n_means)\n",
    "        \n",
    "    return sparse.csr_matrix(fasttext_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.dot(fasttext_ques_matrix, fasttext_ans_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9594)\t0.00961520446305805\n",
      "  (0, 9593)\t0.6523250896695375\n",
      "  (0, 9592)\t-0.13981960271033955\n",
      "  (0, 9591)\t0.4597239541605544\n",
      "  (0, 9590)\t0.6143178112539777\n",
      "  (0, 9589)\t0.03760958256718471\n",
      "  (0, 9588)\t0.32342025915590744\n",
      "  (0, 9587)\t0.2210767609354648\n",
      "  (0, 9586)\t0.32340823608431796\n",
      "  (0, 9585)\t0.2466208661382731\n",
      "  (0, 9584)\t-0.037977391123021724\n",
      "  (0, 9583)\t0.4783842052287916\n",
      "  (0, 9582)\t0.4711405571184212\n",
      "  (0, 9581)\t0.4676759028345956\n",
      "  (0, 9580)\t0.5468900726056373\n",
      "  (0, 9579)\t0.4077364055331764\n",
      "  (0, 9578)\t0.16051731538256986\n",
      "  (0, 9577)\t0.5021259474680448\n",
      "  (0, 9576)\t0.15942950539765396\n",
      "  (0, 9575)\t0.3467151362278232\n",
      "  (0, 9574)\t-0.10333792000843298\n",
      "  (0, 9573)\t0.16081291571106607\n",
      "  (0, 9572)\t0.4957318954832757\n",
      "  (0, 9571)\t0.5596045319624955\n",
      "  (0, 9570)\t-0.09620597406620335\n",
      "  :\t:\n",
      "  (9594, 24)\t-0.08335278662613792\n",
      "  (9594, 23)\t0.14034464419742687\n",
      "  (9594, 22)\t0.03324168959380944\n",
      "  (9594, 21)\t0.25227466990962194\n",
      "  (9594, 20)\t0.020710149434398265\n",
      "  (9594, 19)\t0.24363099288927217\n",
      "  (9594, 18)\t0.17583517236502866\n",
      "  (9594, 17)\t0.06783889706339072\n",
      "  (9594, 16)\t0.137770619273733\n",
      "  (9594, 15)\t0.18727424887086688\n",
      "  (9594, 14)\t-0.02489637573869431\n",
      "  (9594, 13)\t-0.07046440462848184\n",
      "  (9594, 12)\t0.09985593471970618\n",
      "  (9594, 11)\t0.009586137242585165\n",
      "  (9594, 10)\t0.29486081978432527\n",
      "  (9594, 9)\t0.06156000168005692\n",
      "  (9594, 8)\t0.1581918160965743\n",
      "  (9594, 7)\t-0.025068035693633816\n",
      "  (9594, 6)\t0.17186150750513648\n",
      "  (9594, 5)\t0.07403630084408923\n",
      "  (9594, 4)\t0.07924990007268776\n",
      "  (9594, 3)\t0.010793086984415157\n",
      "  (9594, 2)\t0.1852351754841737\n",
      "  (9594, 1)\t0.5033671015033006\n",
      "  (9594, 0)\t0.13281892091556255\n",
      "  (0, 9594)\t0.00961520446305805\n",
      "  (0, 9593)\t0.6523250896695375\n",
      "  (0, 9592)\t-0.13981960271033955\n",
      "  (0, 9591)\t0.4597239541605544\n",
      "  (0, 9590)\t0.6143178112539777\n",
      "  (0, 9589)\t0.03760958256718471\n",
      "  (0, 9588)\t0.32342025915590744\n",
      "  (0, 9587)\t0.2210767609354648\n",
      "  (0, 9586)\t0.32340823608431796\n",
      "  (0, 9585)\t0.2466208661382731\n",
      "  (0, 9584)\t-0.037977391123021724\n",
      "  (0, 9583)\t0.4783842052287916\n",
      "  (0, 9582)\t0.4711405571184212\n",
      "  (0, 9581)\t0.4676759028345956\n",
      "  (0, 9580)\t0.5468900726056373\n",
      "  (0, 9579)\t0.4077364055331764\n",
      "  (0, 9578)\t0.16051731538256986\n",
      "  (0, 9577)\t0.5021259474680448\n",
      "  (0, 9576)\t0.15942950539765396\n",
      "  (0, 9575)\t0.3467151362278232\n",
      "  (0, 9574)\t-0.10333792000843298\n",
      "  (0, 9573)\t0.16081291571106607\n",
      "  (0, 9572)\t0.4957318954832757\n",
      "  (0, 9571)\t0.5596045319624955\n",
      "  (0, 9570)\t-0.09620597406620335\n",
      "  :\t:\n",
      "  (9594, 24)\t-0.08335278662613792\n",
      "  (9594, 23)\t0.14034464419742687\n",
      "  (9594, 22)\t0.03324168959380944\n",
      "  (9594, 21)\t0.25227466990962194\n",
      "  (9594, 20)\t0.020710149434398265\n",
      "  (9594, 19)\t0.24363099288927217\n",
      "  (9594, 18)\t0.17583517236502866\n",
      "  (9594, 17)\t0.06783889706339072\n",
      "  (9594, 16)\t0.137770619273733\n",
      "  (9594, 15)\t0.18727424887086688\n",
      "  (9594, 14)\t-0.02489637573869431\n",
      "  (9594, 13)\t-0.07046440462848184\n",
      "  (9594, 12)\t0.09985593471970618\n",
      "  (9594, 11)\t0.009586137242585165\n",
      "  (9594, 10)\t0.29486081978432527\n",
      "  (9594, 9)\t0.06156000168005692\n",
      "  (9594, 8)\t0.1581918160965743\n",
      "  (9594, 7)\t-0.025068035693633816\n",
      "  (9594, 6)\t0.17186150750513648\n",
      "  (9594, 5)\t0.07403630084408923\n",
      "  (9594, 4)\t0.07924990007268776\n",
      "  (9594, 3)\t0.010793086984415157\n",
      "  (9594, 2)\t0.1852351754841737\n",
      "  (9594, 1)\t0.5033671015033006\n",
      "  (9594, 0)\t0.13281892091556255\n",
      "  (0, 9594)\t0.00961520446305805\n",
      "  (0, 9593)\t0.6523250896695375\n",
      "  (0, 9592)\t-0.13981960271033955\n",
      "  (0, 9591)\t0.4597239541605544\n",
      "  (0, 9590)\t0.6143178112539777\n",
      "  (0, 9589)\t0.03760958256718471\n",
      "  (0, 9588)\t0.32342025915590744\n",
      "  (0, 9587)\t0.2210767609354648\n",
      "  (0, 9586)\t0.32340823608431796\n",
      "  (0, 9585)\t0.2466208661382731\n",
      "  (0, 9584)\t-0.037977391123021724\n",
      "  (0, 9583)\t0.4783842052287916\n",
      "  (0, 9582)\t0.4711405571184212\n",
      "  (0, 9581)\t0.4676759028345956\n",
      "  (0, 9580)\t0.5468900726056373\n",
      "  (0, 9579)\t0.4077364055331764\n",
      "  (0, 9578)\t0.16051731538256986\n",
      "  (0, 9577)\t0.5021259474680448\n",
      "  (0, 9576)\t0.15942950539765396\n",
      "  (0, 9575)\t0.3467151362278232\n",
      "  (0, 9574)\t-0.10333792000843298\n",
      "  (0, 9573)\t0.16081291571106607\n",
      "  (0, 9572)\t0.4957318954832757\n",
      "  (0, 9571)\t0.5596045319624955\n",
      "  (0, 9570)\t-0.09620597406620335\n",
      "  :\t:\n",
      "  (9594, 24)\t-0.08335278662613792\n",
      "  (9594, 23)\t0.14034464419742687\n",
      "  (9594, 22)\t0.03324168959380944\n",
      "  (9594, 21)\t0.25227466990962194\n",
      "  (9594, 20)\t0.020710149434398265\n",
      "  (9594, 19)\t0.24363099288927217\n",
      "  (9594, 18)\t0.17583517236502866\n",
      "  (9594, 17)\t0.06783889706339072\n",
      "  (9594, 16)\t0.137770619273733\n",
      "  (9594, 15)\t0.18727424887086688\n",
      "  (9594, 14)\t-0.02489637573869431\n",
      "  (9594, 13)\t-0.07046440462848184\n",
      "  (9594, 12)\t0.09985593471970618\n",
      "  (9594, 11)\t0.009586137242585165\n",
      "  (9594, 10)\t0.29486081978432527\n",
      "  (9594, 9)\t0.06156000168005692\n",
      "  (9594, 8)\t0.1581918160965743\n",
      "  (9594, 7)\t-0.025068035693633816\n",
      "  (9594, 6)\t0.17186150750513648\n",
      "  (9594, 5)\t0.07403630084408923\n",
      "  (9594, 4)\t0.07924990007268776\n",
      "  (9594, 3)\t0.010793086984415157\n",
      "  (9594, 2)\t0.1852351754841737\n",
      "  (9594, 1)\t0.5033671015033006\n",
      "  (9594, 0)\t0.13281892091556255\n",
      "  (0, 9594)\t0.00961520446305805\n",
      "  (0, 9593)\t0.6523250896695375\n",
      "  (0, 9592)\t-0.13981960271033955\n",
      "  (0, 9591)\t0.4597239541605544\n",
      "  (0, 9590)\t0.6143178112539777\n",
      "  (0, 9589)\t0.03760958256718471\n",
      "  (0, 9588)\t0.32342025915590744\n",
      "  (0, 9587)\t0.2210767609354648\n",
      "  (0, 9586)\t0.32340823608431796\n",
      "  (0, 9585)\t0.2466208661382731\n",
      "  (0, 9584)\t-0.037977391123021724\n",
      "  (0, 9583)\t0.4783842052287916\n",
      "  (0, 9582)\t0.4711405571184212\n",
      "  (0, 9581)\t0.4676759028345956\n",
      "  (0, 9580)\t0.5468900726056373\n",
      "  (0, 9579)\t0.4077364055331764\n",
      "  (0, 9578)\t0.16051731538256986\n",
      "  (0, 9577)\t0.5021259474680448\n",
      "  (0, 9576)\t0.15942950539765396\n",
      "  (0, 9575)\t0.3467151362278232\n",
      "  (0, 9574)\t-0.10333792000843298\n",
      "  (0, 9573)\t0.16081291571106607\n",
      "  (0, 9572)\t0.4957318954832757\n",
      "  (0, 9571)\t0.5596045319624955\n",
      "  (0, 9570)\t-0.09620597406620335\n",
      "  :\t:\n",
      "  (9594, 24)\t-0.08335278662613792\n",
      "  (9594, 23)\t0.14034464419742687\n",
      "  (9594, 22)\t0.03324168959380944\n",
      "  (9594, 21)\t0.25227466990962194\n",
      "  (9594, 20)\t0.020710149434398265\n",
      "  (9594, 19)\t0.24363099288927217\n",
      "  (9594, 18)\t0.17583517236502866\n",
      "  (9594, 17)\t0.06783889706339072\n",
      "  (9594, 16)\t0.137770619273733\n",
      "  (9594, 15)\t0.18727424887086688\n",
      "  (9594, 14)\t-0.02489637573869431\n",
      "  (9594, 13)\t-0.07046440462848184\n",
      "  (9594, 12)\t0.09985593471970618\n",
      "  (9594, 11)\t0.009586137242585165\n",
      "  (9594, 10)\t0.29486081978432527\n",
      "  (9594, 9)\t0.06156000168005692\n",
      "  (9594, 8)\t0.1581918160965743\n",
      "  (9594, 7)\t-0.025068035693633816\n",
      "  (9594, 6)\t0.17186150750513648\n",
      "  (9594, 5)\t0.07403630084408923\n",
      "  (9594, 4)\t0.07924990007268776\n",
      "  (9594, 3)\t0.010793086984415157\n",
      "  (9594, 2)\t0.1852351754841737\n",
      "  (9594, 1)\t0.5033671015033006\n",
      "  (9594, 0)\t0.13281892091556255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13892/3306661451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \"\"\"\n\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m             raise TypeError(\n\u001b[0;32m    512\u001b[0m                 \u001b[1;34mf\"write() argument must be str, not {type(string)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ind, line in enumerate(w):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasttext_ans_matrix = fasttext_get_matrix(cleared_answers_corpus)\n",
    "#fasttext_ques_matrix = fasttext_get_matrix(cleared_questions_corpus)\n",
    "#sparse.save_npz('fasttext_ans_matrix.npz', fasttext_ans_matrix)\n",
    "fasttext_ans_matrix = sparse.load_npz('fasttext_ans_matrix.npz')\n",
    "#sparse.save_npz('fasttext_ques_matrix.npz', fasttext_ques_matrix)\n",
    "fasttext_ques_matrix = sparse.load_npz('fasttext_ques_matrix.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(sparced_matrix, query_vec):\n",
    "    scores = cosine_similarity(sparced_matrix, query_vec)\n",
    "    sorted_scores_indx = np.argsort(scores, axis=0)[::-1]\n",
    "    return list(np.array(answers_corpus)[sorted_scores_indx.ravel()][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_query_preprocessing(query):\n",
    "    query = [word.lower().strip(punctuation).strip() for word in query.split()]\n",
    "    query = m.lemmatize(' '.join([word for word in query]))\n",
    "    query = ' '.join([word for word in query])\n",
    "    tokens = [word for word in query.split() if word != '']\n",
    "    query_vectors = []\n",
    "    tokens_vectors = np.zeros((len(tokens), fasttext_model.vector_size))\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        tokens_vectors[i] = fasttext_model[token]\n",
    "    if tokens_vectors.shape[0] != 0:\n",
    "        means = np.mean(tokens_vectors, axis=0)\n",
    "        n_means = means / np.linalg.norm(means)\n",
    "        query_vectors.append(n_means)\n",
    "\n",
    "        return sparse.csr_matrix(query_vectors)\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_search():\n",
    "    while True:\n",
    "        query = input('–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):')\n",
    "        if query == '–û–°–¢–ê–ù–û–í–ò–¢–ï':\n",
    "            break\n",
    "        start = time()\n",
    "        query_vec = fasttext_query_preprocessing(query)\n",
    "        if query_vec is None:\n",
    "            continue\n",
    "        else:\n",
    "            pprint(get_similarity(fasttext_ques_matrix, query_vec))\n",
    "            end = time()\n",
    "            print('Time spent for search - ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(q_matrix, a_matrix):\n",
    "    #q_matrix = np.delete(q_matrix.toarray(), np.s_[10000:], 0)\n",
    "    #a_matrix = np.delete(a_matrix.toarray(), np.s_[10000:], 0)\n",
    "\n",
    "    scoring_matrix = np.dot(q_matrix, a_matrix.T)\n",
    "    score = 0\n",
    "    for ind, line in enumerate(scoring_matrix):\n",
    "\n",
    "        sorted_scores_indx = np.argsort(line, axis=0)[::-1]\n",
    "        sorted_scores_indx = [sorted_scores_indx.ravel()][0][:5]\n",
    "        if ind in sorted_scores_indx:\n",
    "            score += 1\n",
    "\n",
    "    return score / q_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasttext_ques_matrix.toarray()[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n",
      "0.031370505471599794\n",
      "5.77693247795105\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "print(scoring(fasttext_ques_matrix[:10000].toarray(), fasttext_ans_matrix[:10000].toarray()))\n",
    "end = time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):sdas\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 680. MiB for an array with shape (48582,) and data type <U3667",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2528/2767152671.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfasttext_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2528/3203189.py\u001b[0m in \u001b[0;36mfasttext_search\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfasttext_ques_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time spent for search - '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2528/4200214617.py\u001b[0m in \u001b[0;36mget_similarity\u001b[1;34m(sparced_matrix, query_vec)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparced_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msorted_scores_indx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswers_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msorted_scores_indx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 680. MiB for an array with shape (48582,) and data type <U3667"
     ]
    }
   ],
   "source": [
    "fasttext_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch, torchvision\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
    "auto_model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
    "auto_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_pooling(model_output, attention_mask):\n",
    "    return model_output[0][:,0]\n",
    "\n",
    "def bert_vectorizer(corpus):\n",
    "    corpus = [corpus[i:i + 3250] for i in range(0, len(corpus), 3250)]\n",
    "    bert_vects = []\n",
    "    for text in tqdm(corpus):\n",
    "        encoded_input = auto_tokenizer(text, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
    "        encoded_input = encoded_input.to('cuda')\n",
    "        with torch.no_grad():\n",
    "            model_output = auto_model(**encoded_input)\n",
    "        \n",
    "        sentence_embeddings = cls_pooling(model_output, encoded_input['attention_mask'])\n",
    "        sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings)\n",
    "        for sentence in sentence_embeddings:\n",
    "            bert_vects.append(sentence.cpu().numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return sparse.csr_matrix(bert_vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(bert_vectorizer(questions_corpus), 'ques_bert.pt')\n",
    "#torch.save(bert_vectorizer(answers_corpus), 'ans_bert.pt')\n",
    "b_answers = torch.load('ans_bert.pt')\n",
    "b_questions = torch.load('ques_bert.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_search():\n",
    "    while True:\n",
    "        query = input('–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):')\n",
    "        if query == '–û–°–¢–ê–ù–û–í–ò–¢–ï':\n",
    "            break\n",
    "        query_vec = bert_vectorizer(query)\n",
    "        pprint(get_similarity(b_questions, query_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):–ø–æ—á–µ–º—É –æ–Ω –Ω–µ –¥–∞—Ä–∏—Ç –º–Ω–µ —Ü–≤–µ—Ç—ã?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–¥—É–º–∞—é –æ–± —ç—Ç–æ–º —Å–ª–µ–¥—É–µ—Ç –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å –Ω–∏–º, –∞ –Ω–µ –Ω–∞–º–∏',\n",
      " '–∞ –≤–æ—Ç –µ—Å–ª–∏ –≤ –ø–æ—Å—Ç–µ–ª—å —Å—Ä–∞–∑—É –ø–æ—Ç–∞—â–∏–ª, –ø–∏—Å–∞–ª–∞ –±—ã —Ç—É—Ç, —á—Ç–æ –±–∞–±–Ω–∏–∫ –∏ –∏–∑–≤—Ä–∞—â–µ–Ω–µ—Ü... —á—Ç–æ —Ç–µ–±—è –Ω–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Å–µ–π—á–∞—Å? —Å–∏—Ç–∞—Ä–∞ –º–∞–ª–∏',\n",
      " '–°–ø–æ–π –µ–º—É –ø–µ—Å–Ω—é https://www.youtube.com/watch?v=hme25Nm3JXg',\n",
      " '–°–∫–∞–∂–∏ –µ–º—É \"–º–∏–ª—ã–π, –Ω—É –∫–æ–≥–¥–∞?\"',\n",
      " '–í–∏–¥–∞—Ç—å —Ç—ã —Ö–æ—Ä–æ—à–∞... –≤–æ –≤—Å—ë–º.']\n",
      "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):–û–°–¢–ê–ù–û–í–ò–¢–ï\n"
     ]
    }
   ],
   "source": [
    "bert_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0226\n",
      "7.5947370529174805\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "scoring(b_questions, b_answers)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_query_preprocessing(query, count_vectorizer):\n",
    "    query = [word.lower().strip(punctuation).strip() for word in query.split()]\n",
    "    query = m.lemmatize(' '.join([word for word in query]))\n",
    "    query = ' '.join([word for word in query])\n",
    "    query = ' '.join([word for word in query.split() if word != ''])\n",
    "    query_vec = count_vectorizer.transform([query])\n",
    "    return query_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_vectorization(ans_cleared_corpus, que_cleared_corpus):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    tf_vectorizer = TfidfVectorizer(use_idf=False, norm='l2')\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True, norm='l2')\n",
    "\n",
    "    x_count_vec = count_vectorizer.fit_transform(ans_cleared_corpus)  # –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞\n",
    "    x_tf_vec = tf_vectorizer.fit_transform(ans_cleared_corpus)  # –º–∞—Ç—Ä–∏—Ü–∞ —Å tf\n",
    "    x_tfidf_vec = tfidf_vectorizer.fit_transform(ans_cleared_corpus)  # –º–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è idf\n",
    "    idf = tfidf_vectorizer.idf_\n",
    "    idf = np.expand_dims(idf, axis=0)\n",
    "    tf = x_tf_vec\n",
    "\n",
    "    values = []\n",
    "    rows = []\n",
    "    cols = []\n",
    "    k = 2\n",
    "    b = 0.75\n",
    "\n",
    "    len_d = x_count_vec.sum(axis=1)\n",
    "    avdl = len_d.mean()\n",
    "    B_1 = (k * (1 - b + b * len_d / avdl))\n",
    "\n",
    "    for i, j in zip(*tf.nonzero()):\n",
    "        rows.append(i)\n",
    "        cols.append(j)\n",
    "        A = idf[0][j] * tf[i, j] * k + 1\n",
    "        B = tf[i, j] + B_1[i]\n",
    "        AB = A / B\n",
    "\n",
    "        values.append(np.asarray(AB)[0][0])\n",
    "    \n",
    "    bm25_answers = sparse.csr_matrix((values, (rows, cols)))\n",
    "    bm25_questions = count_vectorizer.transform(que_cleared_corpus)\n",
    "    return bm25_answers, bm25_questions, count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open('bm25_answers.npz', 'rb') as f:\n",
    "        bm25_answers = pickle.load(f)\n",
    "    with open('bm25_questions.npz', 'rb') as f:\n",
    "        bm25_questions = pickle.load(f)\n",
    "    with open('bm25_count_vectorizer.pickle', 'rb') as f:\n",
    "        bm25_count_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x30882 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 106216 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_answers[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_answers, bm25_questions, bm25_count_vectorizer = bm25_vectorization(cleared_answers_corpus[:10000], cleared_questions_corpus[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_tfidf_count_search(vectorizer):\n",
    "    while True:\n",
    "        query = input('–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):')\n",
    "        if query == '–û–°–¢–ê–ù–û–í–ò–¢–ï':\n",
    "            break\n",
    "        query_vec = bm25_query_preprocessing(query, vectorizer)\n",
    "        pprint(get_similarity(bm25_questions, query_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):–∫–∞–∫ –±—Ä–æ—Å–∏—Ç—å –∫—É—Ä–∏—Ç—å\n",
      "['–î–∞, —ç—Ç–æ –≤–µ—Å—å–º–∞ –ø–∞–≥—É–±–Ω–∞—è –ø—Ä–∏–≤—ã—á–∫–∞)–ù–æ –±—É–¥—å –≥–æ—Ç–æ–≤ –∫ —Ç–æ–º—É, —á—Ç–æ —ç—Ç–æ –±—É–¥–µ—Ç –Ω–µ –ª–µ–≥–∫–æ...',\n",
      " '—á—Ç–æ –±—ã –±—ã—Ç—å —Ö–∞—Ä–∏–∑–º–∞—Ç–∏—á–Ω—ã–º–∏, –Ω—É–∂–Ω–æ, –∫–∞–∫ —Ç—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∑–∞–º–µ—Ç–∏–ª–∞, –±—ã—Ç—å —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º–∏, –∞ –¥–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –Ω–∞—É—á–∏—Ç—å—Å—è —Å–µ–±—è –ª—é–±–∏—Ç—å –∏ –Ω–∞–ø–æ–ª–Ω–∏—Ç—å —Å–µ–±—è –¥–æ –∫—Ä–∞—ë–≤ –ª—é–±–æ–≤—å—é, –∞ –≤–æ—Ç –∏–∑–ª–∏—à–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –∏–∑–ª–∏–≤–∞—Ç—å—Å—è –Ω–∞ –æ–∫—Ä—É–∂–∞—é—â–∏—Ö –ª—é–¥–µ–π- —ç—Ç–æ –∏ –µ—Å—Ç—å —Ç–æ —Å–∞–º–æ–µ, —á—Ç–æ –ø—Ä–∏–≤–ª–µ–∫–∞–µ—Ç –æ–∫—Ä—É–∂–∞—é—â–∏—Ö',\n",
      " '–í–∏–¥–Ω–æ —Ä–µ—à–∏–ª —Å –¥–µ—Ç—å–º–∏ –±–æ–ª—å—à–µ –¥–µ–ª –Ω–µ –∏–º–µ—Ç—å.',\n",
      " '—è –±—ã –Ω–µ –∑–∞ –Ω–µ–≥–æ –ø–æ—Ä–∞–¥–æ–≤–∞–ª–∞—Å—å, –∞ –∑–∞ —Å–µ–±—è, —á—Ç–æ —ç—Ç–æ –≤—Å–µ —Ä–∞—Å–∫—Ä—ã–ª–æ—Å—å –¥–æ–≤–æ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–æ –µ—Å—Ç—å —Ç–∞–∫–∏–µ –º—É–∂—á–∏–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–≥–∏–µ –≥–æ–¥—ã –Ω–µ –ø—Ä–æ—è–≤–ª—è—é—Ç —Å–≤–æ—é –ø–æ–¥–ª—É—é –Ω–∞—Ç—É—Ä—É, –∞ –ø–æ—Ç–æ–º –±—Ä–æ—Å–∞—é—Ç –∂–µ–Ω—É —Å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ –¥–µ—Ç—å–º–∏ –∏ —Ñ–æ—Ç–∫–∏ —Å –º–∞–ª—å–¥–∏–≤–æ–≤ —à–ª—é—Ç–≤–ø–æ–ª–Ω–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ–Ω–∞–≤–∏–¥–µ—Ç—å –ø—Ä–µ–¥–∞—Ç–µ–ª—è, –∞ –Ω–µ —Ä–∞–¥–æ–≤–∞—Ç—å—Å—è –∑–∞ –Ω–µ–≥–æ–∏ –∫—Å—Ç–∞—Ç–∏, –æ–Ω –∑–∞ –≤–∞—Å –ø–æ—Ä–∞–¥–æ–≤–∞–ª—Å—è –±—ã –æ–π –∫–∞–∫ –≤—Ä—è–¥ –ª–∏ –≤ —Ç–∞–∫–æ–π –∂–µ —Å–∏—Ç—É–∞—Ü–∏–∏, –∞ –≤–æ–∑–º–æ–∂–Ω–æ –µ—â–µ –∏ –≥–æ—Ä–∞–∑–¥–æ —Ö—É–∂–µ —Ä–µ–∞–∫—Ü–∏—è –±—ã–ª–∞ –±—ã—ç—Ç–æ—Ç —á–µ–ª–æ–≤–µ–∫ –ø—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ —ç–≥–æ–∏—Å—Ç, —è –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é, –∏ –ø–æ–∫–∞ –µ–≥–æ –Ω–µ –∑–∞–¥–µ–≤–∞—é—Ç, –æ–Ω –æ —á—É–≤—Å—Ç–≤–∞—Ö –¥—Ä—É–≥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –æ—á–µ–Ω—å –º–∞–ª–æ –∑–∞–¥—É–º—ã–≤–∞–µ—Ç—Å—è–Ω–∞–≤–µ—Ä–Ω–æ–µ, —ç—Ç–æ –º–Ω–æ–≥–∏–º —Å–≤–æ–π—Å—Ç–≤–µ–Ω–Ω–æ, –Ω–æ –≤—Å–µ —Ç–∞–∫–∏ –µ—Å—Ç—å –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–∫–∏–µ —Ç–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏–≤ –∫–æ–Ω—Ü–µ –∫–æ–Ω—Ü–æ–≤ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –≤—Å–µ –ø–æ–¥–æ–±–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –Ω–∞ —Å–≤–æ–∏ –º–µ—Å—Ç–∞, –∏ –∞–Ω–≥–µ–ª –æ—Å—Ç–∞–µ—Ç—Å—è –∞–Ω–≥–µ–ª–æ–º, –ø–æ–±–µ–¥–∏–≤ —Å–≤–æ—é –æ–±–∏–¥—É, –∞ —ç–≥–æ–∏—Å—Ç –∏—Å–ø—ã—Ç–∞–µ—Ç –≤—Å–µ —Ç–æ, —á—Ç–æ –ø—Ä–∏—á–∏–Ω–∏–ª –¥—Ä—É–≥–æ–º—É))))',\n",
      " '–°—Å–æ—Ä–∏)) –Ω–æ –∏ –Ω–µ –º—É–∂—á–∏–Ω–∞ –∂–µ))))']\n",
      "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):–û–°–¢–ê–ù–û–í–ò–¢–ï\n"
     ]
    }
   ],
   "source": [
    "bm25_tfidf_count_search(bm25_count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ø–∞—Ä—Å –º–∞—Ç—Ä–∏—Ü—ã\n",
    "def scoring_for_count(q_matrix, a_matrix):\n",
    "    # q_matrix = np.delete(q_matrix., np.s_[5000:], 0)\n",
    "    # a_matrix = np.delete(a_matrix.toarray(), np.s_[5000:], 0)\n",
    "    scoring_matrix = np.dot(q_matrix[:10000].toarray(), a_matrix[:10000].toarray().T)\n",
    "    score = 0\n",
    "    for ind, line in enumerate(scoring_matrix):\n",
    "        sorted_scores_indx = np.argsort(line, axis=0)[::-1]\n",
    "        sorted_scores_indx = [sorted_scores_indx.ravel()][0][:5]\n",
    "        if ind in sorted_scores_indx:\n",
    "            score += 1\n",
    "    \n",
    "    print(score/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048\n"
     ]
    }
   ],
   "source": [
    "scoring_for_count(bm25_questions, bm25_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_questions[:10000].toarray()[2].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorization(ans_cleared_corpus, que_cleared_corpus):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_answers = vectorizer.fit_transform(ans_cleared_corpus)\n",
    "    tfidf_questions = vectorizer.transform(que_cleared_corpus)\n",
    "    \n",
    "    return tfidf_answers, tfidf_questions, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_answers, tfidf_questions, tfidf_vectorizer = tfidf_vectorization(cleared_answers_corpus[:10000], cleared_questions_corpus[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):–ø–æ—á–µ–º—É –æ–Ω –Ω–µ –¥–∞—Ä–∏—Ç –º–Ω–µ —Ü–≤–µ—Ç—ã?\n",
      "['–¥—É–º–∞—é –æ–± —ç—Ç–æ–º —Å–ª–µ–¥—É–µ—Ç –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å –Ω–∏–º, –∞ –Ω–µ –Ω–∞–º–∏',\n",
      " '–ü–æ—Ç–æ–º—É —á—Ç–æ –ø–æ—Å–º–æ—Ç—Ä–∏—à—å –Ω–∞ —ç—Ç–∏—Ö –∫–æ—Ä–æ–≤, –∏ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —Ç–≤–æ–π –±—É–∫–µ—Ç —Å–æ–∂—Ä—É—Ç.)',\n",
      " '–í–∏–∫–∞! –Ø - —Ü–≤–µ—Ç—ã –ª—é–±–∏–º–æ–π –Ω–∞ –ö–ê–ñ–î–´–ô –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è!–í—Å–µ–≥–æ 42 —Ä–∞–∑–∞!–ù–∞–¥–µ—é—Å—å!–ü–æ–¥–∞—Ä–∏—Ç—å –µ—â–µ —Ä–∞–∑ –¥–≤–∞–¥—Ü–∞—Ç—å.–í –æ—Å—Ç–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è - —à–æ–∫–æ–ª–∞–¥ –∏ —à–æ–∫–æ–ª–∞–¥–Ω—ã–µ –∫–æ–Ω—Ñ–µ—Ç–∫–∏.–û–Ω–∞ –∏—Ö –æ–±–æ–∂–∞–µ—Ç!',\n",
      " '–õ—é–±–æ–º—É –∞—Ä—Ç–∏—Å—Ç—É –ø—Ä–∏—è—Ç–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Ü–≤–µ—Ç—ã –∏–º–µ–Ω–Ω–æ –Ω–∞ —Å—Ü–µ–Ω–µ. –¢–∞–∫ —á—Ç–æ –¥–∞—Ä–∏—Ç–µ, –Ω–µ —Å—Ç–µ—Å–Ω—è–π—Ç–µ—Å—å!',\n",
      " '–ó–∞–≤–∞—Ä–∫—É']\n",
      "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):–û–°–¢–ê–ù–û–í–ò–¢–ï\n"
     ]
    }
   ],
   "source": [
    "bm25_tfidf_count_search(tfidf_count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0783\n"
     ]
    }
   ],
   "source": [
    "scoring_for_count(tfidf_questions, tfidf_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vectorization(ans_cleared_corpus, que_cleared_corpus):\n",
    "    vectorizer = TfidfVectorizer(use_idf=False, norm='l2')\n",
    "    count_answers = vectorizer.fit_transform(ans_cleared_corpus)\n",
    "    count_questions = vectorizer.transform(que_cleared_corpus)\n",
    "    \n",
    "    return count_answers, count_questions, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_answers, count_questions, count_vectorizer = count_vectorization(cleared_answers_corpus[:10000], cleared_questions_corpus[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):–∫–∞–∫ –±—Ä–æ—Å–∏—Ç—å –∫—É—Ä–∏—Ç—å?\n",
      "['–î–∞, —ç—Ç–æ –≤–µ—Å—å–º–∞ –ø–∞–≥—É–±–Ω–∞—è –ø—Ä–∏–≤—ã—á–∫–∞)–ù–æ –±—É–¥—å –≥–æ—Ç–æ–≤ –∫ —Ç–æ–º—É, —á—Ç–æ —ç—Ç–æ –±—É–¥–µ—Ç –Ω–µ –ª–µ–≥–∫–æ...',\n",
      " '—á—Ç–æ –±—ã –±—ã—Ç—å —Ö–∞—Ä–∏–∑–º–∞—Ç–∏—á–Ω—ã–º–∏, –Ω—É–∂–Ω–æ, –∫–∞–∫ —Ç—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∑–∞–º–µ—Ç–∏–ª–∞, –±—ã—Ç—å —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º–∏, –∞ –¥–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –Ω–∞—É—á–∏—Ç—å—Å—è —Å–µ–±—è –ª—é–±–∏—Ç—å –∏ –Ω–∞–ø–æ–ª–Ω–∏—Ç—å —Å–µ–±—è –¥–æ –∫—Ä–∞—ë–≤ –ª—é–±–æ–≤—å—é, –∞ –≤–æ—Ç –∏–∑–ª–∏—à–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –∏–∑–ª–∏–≤–∞—Ç—å—Å—è –Ω–∞ –æ–∫—Ä—É–∂–∞—é—â–∏—Ö –ª—é–¥–µ–π- —ç—Ç–æ –∏ –µ—Å—Ç—å —Ç–æ —Å–∞–º–æ–µ, —á—Ç–æ –ø—Ä–∏–≤–ª–µ–∫–∞–µ—Ç –æ–∫—Ä—É–∂–∞—é—â–∏—Ö',\n",
      " '–í–∏–¥–Ω–æ —Ä–µ—à–∏–ª —Å –¥–µ—Ç—å–º–∏ –±–æ–ª—å—à–µ –¥–µ–ª –Ω–µ –∏–º–µ—Ç—å.',\n",
      " '—è –±—ã –Ω–µ –∑–∞ –Ω–µ–≥–æ –ø–æ—Ä–∞–¥–æ–≤–∞–ª–∞—Å—å, –∞ –∑–∞ —Å–µ–±—è, —á—Ç–æ —ç—Ç–æ –≤—Å–µ —Ä–∞—Å–∫—Ä—ã–ª–æ—Å—å –¥–æ–≤–æ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–æ –µ—Å—Ç—å —Ç–∞–∫–∏–µ –º—É–∂—á–∏–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–≥–∏–µ –≥–æ–¥—ã –Ω–µ –ø—Ä–æ—è–≤–ª—è—é—Ç —Å–≤–æ—é –ø–æ–¥–ª—É—é –Ω–∞—Ç—É—Ä—É, –∞ –ø–æ—Ç–æ–º –±—Ä–æ—Å–∞—é—Ç –∂–µ–Ω—É —Å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ –¥–µ—Ç—å–º–∏ –∏ —Ñ–æ—Ç–∫–∏ —Å –º–∞–ª—å–¥–∏–≤–æ–≤ —à–ª—é—Ç–≤–ø–æ–ª–Ω–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ–Ω–∞–≤–∏–¥–µ—Ç—å –ø—Ä–µ–¥–∞—Ç–µ–ª—è, –∞ –Ω–µ —Ä–∞–¥–æ–≤–∞—Ç—å—Å—è –∑–∞ –Ω–µ–≥–æ–∏ –∫—Å—Ç–∞—Ç–∏, –æ–Ω –∑–∞ –≤–∞—Å –ø–æ—Ä–∞–¥–æ–≤–∞–ª—Å—è –±—ã –æ–π –∫–∞–∫ –≤—Ä—è–¥ –ª–∏ –≤ —Ç–∞–∫–æ–π –∂–µ —Å–∏—Ç—É–∞—Ü–∏–∏, –∞ –≤–æ–∑–º–æ–∂–Ω–æ –µ—â–µ –∏ –≥–æ—Ä–∞–∑–¥–æ —Ö—É–∂–µ —Ä–µ–∞–∫—Ü–∏—è –±—ã–ª–∞ –±—ã—ç—Ç–æ—Ç —á–µ–ª–æ–≤–µ–∫ –ø—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ —ç–≥–æ–∏—Å—Ç, —è –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é, –∏ –ø–æ–∫–∞ –µ–≥–æ –Ω–µ –∑–∞–¥–µ–≤–∞—é—Ç, –æ–Ω –æ —á—É–≤—Å—Ç–≤–∞—Ö –¥—Ä—É–≥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –æ—á–µ–Ω—å –º–∞–ª–æ –∑–∞–¥—É–º—ã–≤–∞–µ—Ç—Å—è–Ω–∞–≤–µ—Ä–Ω–æ–µ, —ç—Ç–æ –º–Ω–æ–≥–∏–º —Å–≤–æ–π—Å—Ç–≤–µ–Ω–Ω–æ, –Ω–æ –≤—Å–µ —Ç–∞–∫–∏ –µ—Å—Ç—å –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–∫–∏–µ —Ç–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏–≤ –∫–æ–Ω—Ü–µ –∫–æ–Ω—Ü–æ–≤ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –≤—Å–µ –ø–æ–¥–æ–±–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –Ω–∞ —Å–≤–æ–∏ –º–µ—Å—Ç–∞, –∏ –∞–Ω–≥–µ–ª –æ—Å—Ç–∞–µ—Ç—Å—è –∞–Ω–≥–µ–ª–æ–º, –ø–æ–±–µ–¥–∏–≤ —Å–≤–æ—é –æ–±–∏–¥—É, –∞ —ç–≥–æ–∏—Å—Ç –∏—Å–ø—ã—Ç–∞–µ—Ç –≤—Å–µ —Ç–æ, —á—Ç–æ –ø—Ä–∏—á–∏–Ω–∏–ª –¥—Ä—É–≥–æ–º—É))))',\n",
      " '–°—Å–æ—Ä–∏)) –Ω–æ –∏ –Ω–µ –º—É–∂—á–∏–Ω–∞ –∂–µ))))']\n",
      "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):–ø–æ—á–µ–º—É –æ–Ω –Ω–µ –¥–∞—Ä–∏—Ç –º–Ω–µ —Ü–≤–µ—Ç—ã?\n",
      "['–¥—É–º–∞—é –æ–± —ç—Ç–æ–º —Å–ª–µ–¥—É–µ—Ç –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å –Ω–∏–º, –∞ –Ω–µ –Ω–∞–º–∏',\n",
      " '–ü–æ—Ç–æ–º—É —á—Ç–æ –ø–æ—Å–º–æ—Ç—Ä–∏—à—å –Ω–∞ —ç—Ç–∏—Ö –∫–æ—Ä–æ–≤, –∏ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ —Ç–≤–æ–π –±—É–∫–µ—Ç —Å–æ–∂—Ä—É—Ç.)',\n",
      " '–≠—Ç–æ —Ç–∏–ø–∏—á–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –Ω–µ–ø–æ–Ω–∏–º–∞–Ω–∏—è –º–µ–∂–¥—É –º—É–∂—á–∏–Ω–æ–π –∏ –∂–µ–Ω—â–∏–Ω–æ–π. –í–∞–º —Ö–æ—á–µ—Ç—Å—è –≤–Ω–∏–º–∞–Ω–∏—è –∏ —Å–æ—á—É–≤—Å—Ç–≤–∏—è, –∞ –æ–Ω, —Å–ª—ã—à–∞ –∂–∞–ª–æ–±—É, –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞–µ—Ç —ç—Ç–æ –∫–∞–∫ \"–ø—Ä–æ–±–ª–µ–º—É\". –ò –ø–æ-–º—É–∂—Å–∫–∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∫–∞–∫-—Ç–æ –æ—Ç –ø—Ä–æ–±–ª–µ–º—ã –∏–∑–±–∞–≤–∏—Ç—å—Å—è.–ü–æ–≥–æ–≤–æ—Ä–∏—Ç–µ —Å –Ω–∏–º –≤ —Ç–∞–∫–æ–º –∫–ª—é—á–µ, —á—Ç–æ–±—ã –æ–Ω –≤–∞–º –ø–æ—Å–æ—á—É–≤—Å—Ç–≤–æ–≤–∞–ª. –û–ø–∏—à–∏—Ç–µ, –∫–∞–∫ –≤–∞–º –ø–ª–æ—Ö–æ –≤ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥, —á—Ç–æ –≤—ã —á—É–≤—Å—Ç–≤—É–µ—Ç–µ —Å–µ–±—è —Ç–∞–∫–æ–π —Å–ª–∞–±–æ–π –∏ –±–µ—Å–ø–æ–º–æ—â–Ω–æ–π –æ—Ç —ç—Ç–æ–≥–æ, –∏ –≤–∞–º –Ω—É–∂–µ–Ω –∫—Ç–æ-—Ç–æ —Å–∏–ª—å–Ω—ã–π, –∫—Ç–æ –ø–æ–¥–¥–µ—Ä–∂–∏—Ç –∏ –ø–æ—Å–æ—á—É–≤—Å—Ç–≤—É–µ—Ç. –ò –∫–∞–∫ –≤–∞–º —Ö–æ—Ä–æ—à–æ, –∫–æ–≥–¥–∞ –æ–Ω –ø—Ä–æ—è–≤–ª—è–µ—Ç –∫ –≤–∞–º –≤–Ω–∏–º–∞–Ω–∏–µ, –∫–∞–∫ –≤—ã –æ—Ç —ç—Ç–æ–≥–æ —É—Å–ø–æ–∫–∞–∏–≤–∞–∏—Ç–µ—Å—å –∏ –≤—Å–µ —Ç–∞–∫–æ–µ.',\n",
      " '–ê –∑–∞—á–µ–º –µ–º—É —Ä–∞–∑–±–æ—Ä–∫–∏? –µ—Å—Ç—å —Ç–∞–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –º—É–∂—á–∏–Ω, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø—Ä–æ—è–≤–ª—è—é—Ç —Ä–µ–≤–Ω–æ—Å—Ç—å –¥–∞–±—ã –Ω–µ –ø–æ–∫–∞–∑–∞—Ç—å —Å–≤–æ—é –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–µ–±–µ.',\n",
      " '–ø–æ—Ç–æ–º—É —á—Ç–æ —É–∂–µ –Ω–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –Ω—É–∂–µ–Ω –µ—â–µ –∏ –±–∏–ª–µ—Ç –Ω–∞ –ë–∞–≥–∞–º—ã']\n",
      "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ \"–û–°–¢–ê–ù–û–í–ò–¢–ï\" –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏):–û–°–¢–ê–ù–û–í–ò–¢–ï\n"
     ]
    }
   ],
   "source": [
    "bm25_tfidf_count_search(count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11004/476109047.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscoring_for_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_questions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_answers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11004/3482855641.py\u001b[0m in \u001b[0;36mscoring_for_count\u001b[1;34m(q_matrix, a_matrix)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# q_matrix = np.delete(q_matrix., np.s_[5000:], 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# a_matrix = np.delete(a_matrix.toarray(), np.s_[5000:], 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mscoring_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scoring_for_count(count_questions, count_answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
