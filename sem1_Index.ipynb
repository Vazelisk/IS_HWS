{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 1 Индекс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.listdir  \n",
    "возвращает список файлов в данной директории"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обходе файлов не забывайте исключать системные директории, такие как .DS_Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.walk\n",
    "root - начальная директория  \n",
    "dirs - список поддиректорий (папок)   \n",
    "files - список файлов в этих поддиректориях  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример реализации обратного индекса через CountVectorizer. Пользуйтесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[1 1 1 0]\n",
      " [0 1 1 0]\n",
      " [2 1 0 0]\n",
      " [0 0 0 1]] \n",
      "\n",
      "get_feature_names: ['слово1', 'слово2', 'слово3', 'слово4'] \n",
      "\n",
      "vocabulary_.get: 0\n",
      "vocabulary_.get: 3 \n",
      "\n",
      "transform: [[1 0 0 2]]\n",
      "transform: [[0 0 0 0]] \n",
      "\n",
      "matrix_freq: [3 3 2 1] \n",
      "\n",
      "final_matrix: [['слово1' 'слово2' 'слово3' 'слово4']\n",
      " ['3' '3' '2' '1']] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    " \n",
    "# инициализируем\n",
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "\n",
    "# составляем корпус документов\n",
    "corpus = [\n",
    "  'слово1 слово2 слово3',\n",
    "  'слово2 слово3',\n",
    "  'слово1 слово2 слово1',\n",
    "  'слово4'\n",
    "]\n",
    "\n",
    "# считаем\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "# получится следующая структура:\n",
    "#        | слово1 | слово2 | слово3 | слово4\n",
    "# текст1 |   1    |    1   |   1    |   0\n",
    "# текст2 |   0    |    1   |   1    |   0\n",
    "# текст3 |   2    |    1   |   0    |   0\n",
    "# текст4 |   0    |    0   |   0    |   1\n",
    "\n",
    "# показать матрицу\n",
    "print('X:\\n', X.toarray(), '\\n')\n",
    "\n",
    " \n",
    "# чтобы получить сгенерированный словарь, из приведенной структуры CountVectorizer\n",
    "# порядок совпадает с матрицей\n",
    "print('get_feature_names:', vectorizer.get_feature_names(), '\\n')  # ['слово1', 'слово2', 'слово3', 'слово4']\n",
    " \n",
    "    \n",
    "# чтобы узнать индекс токена в словаре\n",
    "print('vocabulary_.get:', vectorizer.vocabulary_.get('слово1')) # вернет 0\n",
    "print('vocabulary_.get:', vectorizer.vocabulary_.get('слово4'), '\\n') # вернет 3\n",
    "\n",
    " \n",
    "# теперь можно быстро подсчитать вектор для нового документа\n",
    "print('transform:', vectorizer.transform(['слово1 слово4 слово4']).toarray())  # результат [[1 0 0 2]]\n",
    "print('transform:', vectorizer.transform(['слово5']).toarray(), '\\n')\n",
    "\n",
    " \n",
    "# чтобы узнать количественное вхождение каждого слова:\n",
    "matrix_freq = np.asarray(X.sum(axis=0)).ravel()\n",
    "print('matrix_freq:', matrix_freq, '\\n')  # результат [3 3 2 1] \n",
    "\n",
    "final_matrix = np.array([np.array(vectorizer.get_feature_names()), matrix_freq])\n",
    "print('final_matrix:', final_matrix, '\\n')  # результат [['слово1' 'слово2' 'слово3' 'слово4'], ['3' '3' '2' '1']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [2, 1, 0, 0],\n",
       "       [0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['слово1 слово4 слово4']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Индекс \n",
    "\n",
    "Сам по себе индекс - это просто формат хранения данных, он не может осуществлять поиск. Для этого необходимо добавить к нему определенную метрику. Это может быть что-то простое типа булева поиска, а может быть что-то более специфическое или кастомное под задачу.\n",
    "\n",
    "Давайте посмотрим, что полезного можно вытащить из самого индекса.    \n",
    "Например, индекс - это информация о частоте встречаемости слова в каждом документе.   \n",
    "Из этого можно понять, например:\n",
    "1. какое слово является самым часто употребимым / редким\n",
    "2. какие слова встречаются всегда вместе - так можно парсить твиттер, fb, форумы и отлавливать новые устойчивые выражения в речи\n",
    "3. как эти документы кластеризуются по N тематикам согласно словам, которые в них упоминаются "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Задача__: \n",
    "\n",
    "**Data:** Коллекция субтитров сезонов Друзей. Одна серия - один документ.\n",
    "\n",
    "**To do:** \n",
    "\n",
    "**1 Создайте обратный индекс этой базы, используя CountVectorizer. \n",
    "То, что вы получите, называется матрица Term-Document.**\n",
    "\n",
    "Компоненты вашей реализации:\n",
    "    - Функция препроцессинга данных. Включите туда лемматизацию, приведение к одному регистру, удаление пунктуации и стоп-слов.\n",
    "    - Функция индексирования данных. На выходе создает обратный индекс, он же матрица Term-Document.\n",
    "\n",
    "**2 С помощью обратного индекса посчитайте:** \n",
    "\n",
    "\n",
    "a) какое слово является самым частотным\n",
    "\n",
    "b) какое самым редким\n",
    "\n",
    "c) какой набор слов есть во всех документах коллекции\n",
    "\n",
    "d) кто из главных героев статистически самый популярный (упонимается чаще всего)? Имена героев:\n",
    "- Моника\n",
    "- Рэйчел \n",
    "- Чендлер\n",
    "- Фиби\n",
    "- Росс\n",
    "- Джоуи, Джои\n",
    "\n",
    "**На что направлены эти задачи:** \n",
    "1. Навык построения обратного индекса\n",
    "2. Навык работы с этим индексом, а именно как с помощью numpy или pandas достать нужную информацию из матрицы данных\n",
    "\n",
    "[download_friends_corpus](https://yadi.sk/d/4wmU7R8JL-k_RA?w=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "sub_dir = os.path.join(curr_dir, 'friends-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for root, dirs, files in os.walk(curr_dir):\n",
    "    for name in files:\n",
    "        if name.endswith('txt'):\n",
    "            paths.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\trekc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preproc(path):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    with open(path, 'r', encoding='utf-8-sig') as f:\n",
    "        text = f.read()\n",
    "        text = [word.lower().strip(punctuation) for word in text.split()]\n",
    "        text = [word for word in text if word not in stopwords.words('russian')]\n",
    "        text = [word for word in text if word != '']\n",
    "        del text[-4:] # meta info\n",
    "    \n",
    "    lemmas = str()\n",
    "    known_words = {}\n",
    "\n",
    "    for word in text:\n",
    "        if word in known_words:\n",
    "            lemmas += (known_words[word] + ' ')\n",
    "        else:\n",
    "            result = morph.parse(word)[0].normal_form\n",
    "            lemmas += (result + ' ')\n",
    "            known_words[word] = result\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 165/165 [01:50<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "texts = []\n",
    "for path in tqdm(paths):\n",
    "    processed = preproc(path)\n",
    "    texts.append(processed)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "X = vectorizer.fit_transform(texts).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>009</th>\n",
       "      <th>02</th>\n",
       "      <th>038</th>\n",
       "      <th>03815</th>\n",
       "      <th>0fps</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>ёвить</th>\n",
       "      <th>ёй</th>\n",
       "      <th>ёкнуть</th>\n",
       "      <th>ёлка</th>\n",
       "      <th>ёлочный</th>\n",
       "      <th>ёпэрэсотэ</th>\n",
       "      <th>ёрл</th>\n",
       "      <th>ёрш</th>\n",
       "      <th>ёршик</th>\n",
       "      <th>ёще</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 15146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00  000  007  009  02  038  03815  0fps  10  100  ...  ёвить  ёй  ёкнуть  \\\n",
       "0     0    0    0    0   0    0      0     0   0    0  ...      0   0       0   \n",
       "1     0    0    0    0   0    0      0     0   0    0  ...      0   0       0   \n",
       "2     0    0    0    0   0    0      0     0   0    0  ...      0   0       0   \n",
       "3     0    0    0    0   0    0      0     0   0    0  ...      0   0       0   \n",
       "4     0    0    0    0   0    0      0     0   0    0  ...      0   0       0   \n",
       "..   ..  ...  ...  ...  ..  ...    ...   ...  ..  ...  ...    ...  ..     ...   \n",
       "160   0    0    7    0   0    0      0     0   1    0  ...      0   0       0   \n",
       "161   0    0    0    0   0    0      0     0   0    0  ...      0   0       0   \n",
       "162   0    0    0    0   0    0      0     0   1    0  ...      0   0       0   \n",
       "163   0    0    0    0   0    0      0     0   0    0  ...      0   0       0   \n",
       "164   0    0    0    0   0    0      0     0   0    0  ...      0   0       0   \n",
       "\n",
       "     ёлка  ёлочный  ёпэрэсотэ  ёрл  ёрш  ёршик  ёще  \n",
       "0       0        0          0    0    0      0    0  \n",
       "1       0        0          0    0    0      0    0  \n",
       "2       0        0          0    0    0      0    0  \n",
       "3       0        0          0    0    0      0    0  \n",
       "4       0        0          0    0    0      0    0  \n",
       "..    ...      ...        ...  ...  ...    ...  ...  \n",
       "160     0        0          0    0    0      0    0  \n",
       "161     0        0          0    0    0      0    0  \n",
       "162     0        0          0    0    0      0    0  \n",
       "163     0        0          0    0    0      0    0  \n",
       "164     0        0          0    0    0      0    0  \n",
       "\n",
       "[165 rows x 15146 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(X, columns = vectorizer.get_feature_names())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "это    6573\n",
       "dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer[summarizer == summarizer.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "03815      1\n",
       "0fps       1\n",
       "101        1\n",
       "102        1\n",
       "110        1\n",
       "          ..\n",
       "ёлочный    1\n",
       "ёрл        1\n",
       "ёрш        1\n",
       "ёршик      1\n",
       "ёще        1\n",
       "Length: 6866, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer[summarizer == summarizer.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mms(data):\n",
    "    summarizer = data.sum()\n",
    "    max_value = summarizer[summarizer == summarizer.max()]\n",
    "    min_value = summarizer[summarizer == summarizer.min()]\n",
    "    print(max_value)\n",
    "    print(min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "это    6573\n",
      "dtype: int64\n",
      "03815      1\n",
      "0fps       1\n",
      "101        1\n",
      "102        1\n",
      "110        1\n",
      "          ..\n",
      "ёлочный    1\n",
      "ёрл        1\n",
      "ёрш        1\n",
      "ёршик      1\n",
      "ёще        1\n",
      "Length: 6866, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "get_mms(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "inclusive = list()\n",
    "for word, index in data.iteritems():\n",
    "    temp = []\n",
    "    for item in index:\n",
    "        if item > 0:\n",
    "            temp.append(word)\n",
    "    if len(temp) == 165:\n",
    "        inclusive.append(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['думать', 'знать', 'просто', 'сказать', 'ты', 'хотеть', 'это']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "charac = {\n",
    "    'Моника': 0,\n",
    "    'Рэйчел': 0,\n",
    "    'Чендлер': 0,\n",
    "    'Фиби': 0,\n",
    "    'Росс': 0,\n",
    "    'Джоуи': 0\n",
    "}\n",
    "\n",
    "\n",
    "for index, numbers in data.iteritems():\n",
    "    if index == 'моника' or index == 'мон':\n",
    "        for number in numbers:\n",
    "            charac['Моника'] += number\n",
    "\n",
    "    if index == 'рэйчел' or index == 'рейч':\n",
    "        for number in numbers:\n",
    "            charac['Рэйчел'] += number            \n",
    "            \n",
    "    if index == 'чендлер' or index == 'чэндлер' or index == 'чен':\n",
    "        for number in numbers:\n",
    "            charac['Чендлер'] += number\n",
    "\n",
    "    if index == 'фиби' or index == 'фибс':\n",
    "        for number in numbers:\n",
    "            charac['Фиби'] += number\n",
    "\n",
    "    if index == 'росс':\n",
    "        for number in numbers:\n",
    "            charac['Росс'] += number\n",
    "\n",
    "    if index == 'Джоуи' or index == 'джои' or index == 'джо':\n",
    "        for number in numbers:\n",
    "            charac['Джоуи'] += number\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Росс', 1016)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(charac, key=charac.get), max(charac.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
